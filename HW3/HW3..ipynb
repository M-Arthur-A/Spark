{
  "metadata": {
    "name": "HW3",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\nНужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\"37.139.32.56:8088/proxy/\" + sc.applicationId"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\n\nval dates \u003d (0 to 7).map(LocalDate.of(2020, 11, 1).plusDays(_).format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))).toSeq\n\ndef generateCity(r: Double): String \u003d if (r \u003c 0.9) \"BIG_CITY\" else \"SMALL_CITY_\" + scala.math.round((r - 0.9) * 1000)\n\ndef generateCityUdf \u003d udf(generateCity _)\n\n// spark.sql(\"drop table hw2.events_full\")\n\nfor(i \u003c- dates) {\n    uniformRDD(sc, 10000000L, 1)\n    .toDF(\"uid\")\n    .withColumn(\"date\", lit(i))\n    .withColumn(\"city\", generateCityUdf($\"uid\"))\n    .selectExpr(\"date\", \" sha2(cast(uid as STRING), 256) event_id\", \"city\")\n    .withColumn(\"skew_key\", when($\"city\" \u003d\u003d\u003d \"BIG_CITY\", lit(\"big_event\")).otherwise($\"event_id\"))\n    .write.mode(\"append\")\n    .partitionBy(\"date\")\n    .saveAsTable(\"hw2.events_full\")\n}\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.001)\n.repartition(2)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nspark.table(\"hw2.sample\")\n.limit(100)\n.coalesce(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_small\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.006)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_big\")"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.03)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_very_big\")"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.table(\"hw2.events_full\").count"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Для упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера hw2.sample_[small, big, very_big]. \n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n "
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nspark.table(\"hw2.events_full\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -ls -h /apps/spark/warehouse/hw2.db\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\ndf_sample \u003d spark.table(\u0027hw2.sample\u0027)\ndf_sample_small \u003d spark.table(\u0027hw2.sample_small\u0027)\ndf_events_full \u003d spark.table(\u0027hw2.events_full\u0027)\ndf_sample_big \u003d spark.table(\u0027hw2.sample_big\u0027)\ndf_sample_very_big \u003d spark.table(\u0027hw2.sample_very_big\u0027)\n\ndf_sample.show()\ndf_sample.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport sys\ndfs \u003d [df_events_full, df_sample, df_sample_small, df_sample_big, df_sample_very_big]\ndfs_names \u003d [\u0027df_events_full\u0027, \u0027df_sample\u0027, \u0027df_sample_small\u0027, \u0027df_sample_big\u0027, \u0027df_sample_very_big\u0027]\nfor i, df in enumerate(dfs):\n    print(\u0027{} contains {} rows\u0027.format( dfs_names[i], df.count() ))\n# print()\n# for i, df in enumerate(dfs):\n#     print(\u0027{} size is {}\u0027.format( dfs_names[i], sys.getsizeof(df) ))"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nhdfs dfs -du -h /apps/spark/warehouse/hw2.db "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "* **структура таблиц** представлена одним столбцом \"`event_id`\" в string-формате, содержащий сгенерированные хэши\n* **всего записей в таблицах**:\n    * `df_events_full` contains 80000000 rows\n    * `df_sample` contains 80271 rows\n    * `df_sample_small` contains 100 rows\n    * `df_sample_big` contains 479793 rows\n    * `df_sample_very_big` contains 2401149 rows\n* **занимаемое место**:\n    * `df_events_full` -- 5.3 G\n    * `df_sample` -- 4.9 M\n    * `df_sample_small` -- 29.1 M\n    * `df_sample_big` -- 7.0 K\n    * `df_sample_very_big` -- 145.8 M"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nПолучить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin? \n\nBroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")."
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprint(\"spark.sql.autoBroadcastJoinThreshold \u003d {}\".format(spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")))\n\nprint(\u0027full+sample\u0027)\nspark.table(\"hw2.events_full\")\\\n.join(spark.table(\"hw2.sample\"), \"event_id\")\\\n.explain()\nprint(\u0027\u0027)\nprint(\u0027full+big\u0027)\nspark.table(\"hw2.events_full\")\\\n.join(df_sample_big, \"event_id\")\\\n.explain()\nprint(\u0027\u0027)\nprint(\u0027full+very_big\u0027)\nspark.table(\"hw2.events_full\")\\\n.join(df_sample_very_big, \"event_id\")\\\n.explain()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**BroadcastHashJoin использует join с sample. С big и very_big используется SortMergeJoin**, начиная с 25.6 Мб"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nВыполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n\nЗайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?  "
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nspark.table(\"hw2.events_full\")\\\n.join(df_sample, \"event_id\")\\\n.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nspark.table(\"hw2.events_full\")\\\n.join(df_sample_big, \"event_id\")\\\n.count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- **При join sample образца было задействовано 2 stages c 43 tasks суммарно, выполнено за 45 секунд**\n- **При join sample образца было задействовано 4 stages (видимо требуется более распределенное вычисление), выбивает с ошибкой \"python process is abnormally exited, please check your code and log.\"**"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")\nprintln(\"37.139.32.56:8088/proxy/\" + sc.applicationId + \"/jobs/\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится "
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\n\nprint(\"37.139.32.56:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n\nspark.table(\"hw2.events_full\")\\\n.join(f.broadcast(spark.table(\"hw2.sample\")), \"event_id\")\\\n.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\n\nprint(\"37.139.32.56:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n\nspark.table(\"hw2.events_full\")\\\n.join(spark.table(\"hw2.sample\"), \"event_id\")\\\n.count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nОтключить автоматический броадкаст командой spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\"). Сделать джойн с семплом hw2.sample, сравнить время выполнения запроса.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\n\nprint(\"37.139.32.56:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n\nspark.table(\"hw2.events_full\")\\\n.join(spark.table(\"hw2.sample\"), \"event_id\")\\\n.count()\n\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"clear cache\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**С отключенном broadcast операция выполнялась больше минуты и не выполнилaсь. При этом количество stages увеличилось с 2 до 4**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nВ процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.\n\nДатафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение."
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \nimport pyspark.sql.functions as f\n\nskew_df \u003d spark.table(\"hw2.events_full\")\\\n.where(\"date \u003d \u00272020-11-01\u0027\")\\\n.repartition(30, f.col(\"city\"))\\\n.cache()\n\nskew_df.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(skew_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nПосчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.\n\nВ spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют -- это и является проблемой, которую предлагается решить далее."
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nskew_df\\\n.select(\u0027event_id\u0027, \u0027city\u0027)\\\n.groupby(\u0027city\u0027)\\\n.agg(f.count(\u0027*\u0027).alias(\u0027event_count\u0027))\\\n.orderBy(\u0027event_count\u0027, ascending\u003dFalse)\\\n.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nодин из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num -- количество партиций, на которые будет перемешан исходный датафрейм"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nskew_df \u003d skew_df.repartition(30)\n\nskew_df\\\n.select(\u0027event_id\u0027, \u0027city\u0027)\\\n.groupby(\u0027city\u0027)\\\n.agg(f.count(\u0027*\u0027).alias(\u0027event_count\u0027))\\\n.orderBy(\u0027event_count\u0027, ascending\u003dFalse)\\\n.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\nДругой способ исправить неравномерность по ключу -- создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city\u003d\u0027BIG_CITY\u0027, которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand -- случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным. \n\nТакая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8\n\nЧто нужно реализовать:\n* добавить синтетический ключ\n* группировка по синтетическому ключу\n* восстановление исходного значения\n* группировка по исходной колонке"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# initial\nskew_df \u003d spark.table(\"hw2.events_full\")\\\n.where(\"date \u003d \u00272020-11-01\u0027\")\\\n.repartition(30, f.col(\"city\"))\\\n.cache()\n\n# salting\nsalt \u003d f.expr(\"\"\"pmod(round(rand() * 100, 0), 10)\"\"\").cast(\"integer\")\nsalted \u003d skew_df.withColumn(\"salt\", salt)"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nsalted\\\n.groupby(f.col(\u0027city\u0027), f.col(\u0027salt\u0027)).count().alias(\u0027event_count\u0027)\\\n.groupby(f.col(\u0027city\u0027)).sum()\\\n.orderBy(\u0027sum(count)\u0027, ascending\u003dFalse)\\\n.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprint(\"37.139.32.56:8088/proxy/\" + sc.applicationId + \"/jobs/\")"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.stop"
    }
  ]
}